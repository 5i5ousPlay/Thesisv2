{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup in Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install\n",
    "%pip install worker\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install networkx\n",
    "%pip install matplotlib\n",
    "%pip install music21\n",
    "%pip install musescore\n",
    "%pip install tslearn\n",
    "%pip install sklearn\n",
    "%pip install multiprocessing\n",
    "%pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import worker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from music21 import *\n",
    "from music21 import converter, corpus, environment, note, chord\n",
    "from tslearn.metrics import dtw\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from networkx.algorithms.cuts import conductance\n",
    "from pyvis.network import Network\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "env = environment.Environment()\n",
    "env['musicxmlPath'] = 'C:\\\\Program Files\\\\MuseScore 4\\\\bin\\\\MuseScore4.exe' # Change if needed\n",
    "env['musescoreDirectPNGPath'] = 'C:\\\\Program Files\\\\MuseScore 4\\\\bin\\\\MuseScore4.exe' # Change if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Sample Music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi to score array function (contains all data needed for score visualization)\n",
    "def midi_to_sarr(midi_parsed):\n",
    "    sarr = []\n",
    "    for part in midi_parsed.parts:\n",
    "        for element in part.flatten():\n",
    "            sarr.append(element)\n",
    "    return sarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sarr to narr and nmat function (removes all elements except notes, rests and chords then turn it into a matrix )\n",
    "def sarr_to_nmat_and_narr(score_array):\n",
    "  trashed_elements = 0\n",
    "  narr = []\n",
    "  nmat = pd.DataFrame(columns=['onset_beats', 'duration_beats', 'midi_pitch'])\n",
    "\n",
    "  for element in score_array:\n",
    "    if isinstance(element, chord.Chord):\n",
    "      row = [element.offset, element.duration.quarterLength, element.root().midi]\n",
    "      nmat.loc[len(nmat)] = row\n",
    "      narr.append(element)\n",
    "    elif isinstance(element, note.Rest):\n",
    "      row = [element.offset, element.duration.quarterLength, 0]\n",
    "      nmat.loc[len(nmat)] = row\n",
    "      narr.append(element)    \n",
    "    else:\n",
    "      try:\n",
    "        row = [element.offset, element.duration.quarterLength, element.pitch.midi]\n",
    "        nmat.loc[len(nmat)] = row\n",
    "        narr.append(element)\n",
    "      except:\n",
    "        trashed_elements += 1\n",
    "        # print(f\"Trashed element #{trashed_elements}:\\n{note}\") # for debugging\n",
    "  return nmat, narr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the midi and keep score title\n",
    "midi_file = 'bach_846.mid' # Hardcoded, for multiple songs, make a function to iterate thru folder\n",
    "midi_parsed = converter.parse(midi_file)\n",
    "score_title = midi_file[:-4] # Temporary, apparently the title is not a score element that you can extract so im using the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert parsed midi into a readable array of elements that forms the score\n",
    "sarr = midi_to_sarr(midi_parsed) # this midi was cleaned\n",
    "\n",
    "# output sarr to a readable .txt file\n",
    "with open(\"sarr_output.txt\", \"w\") as f:\n",
    "    f.write(f\"Number of elements: {len(sarr)}\\n\\n\")\n",
    "    for element in sarr:\n",
    "        f.write(f\"{element}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert score array into a note array and note matrix\n",
    "nmat, narr = sarr_to_nmat_and_narr(sarr)\n",
    "\n",
    "# output nmat to a readable .txt file\n",
    "with open(\"nmat_output.txt\", \"w\") as f:\n",
    "    f.write(f\"Number of notes: {len(nmat)}\\n\\n\")\n",
    "    for note in nmat:\n",
    "        f.write(f\"{note}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    np.savetxt('nmat_output.txt', nmat, delimiter=',', fmt='%s')\n",
    "\n",
    "# output narr to a readable .txt file\n",
    "with open(\"narr_output.txt\", \"w\") as f:\n",
    "    f.write(f\"Number of notes: {len(narr)}\\n\\n\")\n",
    "    for note in narr:\n",
    "        f.write(f\"{note}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implication-Realization Ruleset, Assignment and Score Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR symbol calculation function\n",
    "def calculate_ir_symbol(interval1, interval2, threshold=5):\n",
    "    direction = interval1 * interval2\n",
    "    abs_difference = abs(interval2-interval1)\n",
    "    # Process\n",
    "    if direction > 0 and (abs(interval2-interval1))<threshold:\n",
    "        return 'P'  \n",
    "    # IR2: D (Duplication)\n",
    "    elif interval1 == interval2 == 0:\n",
    "        return 'D' \n",
    "    # IR3: IP (Intervallic Process)\n",
    "    elif ((interval1 * interval2)<0) and (-threshold <= (abs(interval2) - abs(interval1)) <= threshold) and (abs(interval2) != abs(interval1)):\n",
    "        return 'IP' \n",
    "    # IR4: ID (Intervallic Duplication)\n",
    "    elif ((interval1 * interval2) < 0) and (abs(interval2) == abs(interval1)):\n",
    "        return 'ID'   \n",
    "    # IR5: VP (Vector Process)\n",
    "    elif (interval1 * interval2 > 0) and (abs(interval2-interval1) >= threshold) and (abs(interval1) <= threshold):\n",
    "        return 'VP'\n",
    "    # IR6: R (Reveral)\n",
    "    elif (interval1 * interval2 < 0) and (abs(abs(interval2)-abs(interval1)) >= threshold) and (abs(interval1) >= threshold):\n",
    "        return 'R'\n",
    "    # IR7: IR (Intervallic Reveral)\n",
    "    elif (interval1 * interval2 > 0) and (abs(abs(interval2)-abs(interval1)) >= threshold) and (abs(interval1) >= threshold):\n",
    "        return 'IR' \n",
    "    # IR8: VR (Vector Reveral)\n",
    "    elif (interval1 * interval2 < 0) and (abs(interval2 - interval1) >= threshold) and (abs(interval1) <= threshold):\n",
    "        return 'VR'\n",
    "    elif interval2 == 0 and not (interval1 < -5 or interval1 > 5):\n",
    "        return 'IP'\n",
    "    elif interval2 == 0 and (interval1 < -5 or interval1 > 5):\n",
    "        return 'R'\n",
    "    elif interval1 == 0 and not (interval2 < -5 or interval2 > 5):\n",
    "        return 'P'\n",
    "    elif interval1 == 0 and (interval2 < -5 or interval2 > 5):\n",
    "        return 'VR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign IR symbol function (original; modified)\n",
    "def assign_ir_symbols(score_array):\n",
    "\n",
    "    symbols = []\n",
    "    current_group = [] \n",
    "    group_pitches = []\n",
    "    \n",
    "    color_map = {\n",
    "        'P': 'blue',        # IR1: P (Process) \n",
    "        'D': 'green',       # IR2: D (Duplication)\n",
    "        'IP': 'red',        # IR3: IP (Intervallic Process)\n",
    "        'ID': 'orange',     # IR4: ID (Intervallic Duplication)\n",
    "        'VP': 'purple',     # IR5: VP (Vector Process)\n",
    "        'R': 'cyan',        # IR6: R (Reveral)\n",
    "        'IR': 'magenta',    # IR7: IR (Intervallic Reveral)\n",
    "        'VR': 'yellow',     # IR8: VR (Vector Reveral)\n",
    "        'M': 'pink',        # IR9: M (Monad)\n",
    "        'd': 'lime',        # IR10 d (Dyad)\n",
    "    }\n",
    "\n",
    "    def evaluate_current_group():\n",
    "        if len(current_group) == 3:\n",
    "            interval1 = group_pitches[1] - group_pitches[0]\n",
    "            interval2 = group_pitches[2] - group_pitches[1]\n",
    "            symbol = calculate_ir_symbol(interval1, interval2)\n",
    "            # symbols.append(symbol)\n",
    "            color = color_map.get(symbol, 'black')  # Default to black if symbol is not predefined\n",
    "            symbols.extend((note, symbol, color) for note in current_group)\n",
    "        elif len(current_group) == 2:\n",
    "            # symbols.append('d')  # Dyad\n",
    "            symbols.extend((note, 'd', color_map['d']) for note in current_group)\n",
    "        elif len(current_group) == 1:\n",
    "            # symbols.append('M')  # Monad\n",
    "            symbols.extend((note, 'M', color_map['M']) for note in current_group)\n",
    "        # else:\n",
    "            # symbols.append('Error: Invalid note object')\n",
    "        current_group.clear()\n",
    "        group_pitches.clear()\n",
    "\n",
    "    for element in score_array:\n",
    "        if isinstance(element, note.Note):\n",
    "            current_group.append(element)\n",
    "            group_pitches.append(element.pitch.ps)\n",
    "            if len(current_group) == 3:\n",
    "                evaluate_current_group()\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            current_group.append(element)\n",
    "            group_pitches.append(element.root().ps)\n",
    "            if len(current_group) == 3:\n",
    "                evaluate_current_group()\n",
    "        elif isinstance(element, note.Rest):\n",
    "            # continue\n",
    "            # Remove continue for visualization\n",
    "            rest_tuple = (element, 'rest', 'black') \n",
    "            evaluate_current_group()\n",
    "            symbols.append(rest_tuple)\n",
    "        else:\n",
    "            if current_group:\n",
    "                evaluate_current_group()\n",
    "\n",
    "    # Handle any remaining notes\n",
    "    if current_group:\n",
    "        evaluate_current_group()\n",
    "\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score visualization function\n",
    "def visualize_notes_with_symbols(notes_with_symbols):\n",
    "    s = stream.Score()\n",
    "    part = stream.Part()\n",
    "    for note, symbol, color in notes_with_symbols:\n",
    "        print(note, symbol, color)\n",
    "        note.style.color = color\n",
    "        note.lyric = symbol\n",
    "        part.append(note)\n",
    "    s.append(part)\n",
    "    s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE REVISED TOMORROW START HERE\n",
    "\n",
    "# testscore = sarr # make the new score\n",
    "# music21.stream.base.Score\n",
    "# testscore.show(\"midi\")\n",
    "\n",
    "# Usage of the above functions\n",
    "test_ir = assign_ir_symbols(narr)\n",
    "\n",
    "# output narr to a readable .txt file\n",
    "with open(\"test_ir_output.txt\", \"w\") as f:\n",
    "    f.write(f\"Number of notes: {len(test_ir)}\\n\\n\")\n",
    "    for note in test_ir:\n",
    "        f.write(f\"{note}\\n\")\n",
    "\n",
    "# try: # error when polyphonic\n",
    "visualize_notes_with_symbols(test_ir)\n",
    "# except:\n",
    "#     score = converter.parse('bach_846.mid')\n",
    "#     score.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestalt Based Segmentation (Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onset function\n",
    "def get_onset(notematrix: pd.DataFrame, timetype='beat'):\n",
    "  if timetype == 'beat':\n",
    "    return notematrix['onset_beats']\n",
    "  elif timetype == 'sec':\n",
    "    return notematrix['onset_sec']\n",
    "  else:\n",
    "    ValueError(f\"Invalid timetype: {timetype}. Choices are only 'beat' and 'sec'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration function\n",
    "def get_duration(notematrix: pd.DataFrame, timetype='beat') -> pd.Series:\n",
    "  if timetype == 'beat':\n",
    "    return notematrix['duration_beats']\n",
    "  elif timetype == 'sec':\n",
    "    return notematrix['duration_sec']\n",
    "  else:\n",
    "    ValueError(f\"Invalid timetype: {timetype}. Choices are only 'beat' and 'sec'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clang boundary calculation funtion\n",
    "def calculate_clang_boundaries(notematrix: pd.DataFrame):\n",
    "  cl = 2*(get_onset(notematrix).diff() + get_duration(notematrix).shift(-1)) + abs(notematrix['midi_pitch'].diff())\n",
    "  clb = (cl.shift(-1) > cl) & (cl.shift(1) > cl)\n",
    "  clind = clb.index[clb].tolist()\n",
    "  return clind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment boundary calculation function\n",
    "def calculate_segment_boundaries(notematrix, clind):\n",
    "    first = [0] + clind\n",
    "    last = clind + [len(notematrix) - 1]\n",
    "    mean_pitch = [notematrix.iloc[first[i]:last[i]+1]['midi_pitch'].mean() for i in range(len(first))]\n",
    "    segdist = []\n",
    "    for i in range(1, len(first)):\n",
    "        segdist.append(abs(mean_pitch[i] - mean_pitch[i - 1]) +\n",
    "                       notematrix.iloc[first[i]]['onset_beats'] - notematrix.iloc[last[i - 1]]['onset_beats'] +\n",
    "                       notematrix.iloc[first[i]]['duration_beats'] + notematrix.iloc[first[i - 1]]['duration_beats'] +\n",
    "                       2 * (notematrix.iloc[first[i]]['onset_beats'] - notematrix.iloc[last[i - 1]]['onset_beats']))\n",
    "\n",
    "    segb = [(segdist[i] > segdist[i-1] and segdist[i] > segdist[i+1]) for i in range(1, len(segdist)-1)]\n",
    "    segind = [clind[i] for i in range(1, len(segdist)-1) if segb[i-1]]\n",
    "    return segind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gestalt segmentation function\n",
    "def segmentgestalt(notematrix):\n",
    "    if notematrix.empty:\n",
    "        return None\n",
    "\n",
    "    # IR Assignment function here? <------------------------------------------------------ yayayaya look here\n",
    "    clind = calculate_clang_boundaries(notematrix)\n",
    "    segind = calculate_segment_boundaries(notematrix, clind)\n",
    "\n",
    "    segments = []\n",
    "    start_idx = 0\n",
    "    for end_idx in segind:\n",
    "        segments.append(notematrix.iloc[start_idx:end_idx+1])\n",
    "        start_idx = end_idx + 1\n",
    "\n",
    "    segments.append(notematrix.iloc[start_idx:])\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Clang Boundaries and Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show clang boundaries\n",
    "clang_boundaries = calculate_clang_boundaries(nmat)\n",
    "print(\"Clang Boundaries:\", clang_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segments\n",
    "segments = segmentgestalt(nmat)\n",
    "\n",
    "# Store viz related properties (score title, color), labelling the segment\n",
    "labeled_segments = []\n",
    "assigned_color = 'red' # HARDCODED temporary since multiple scores not impremented yet\n",
    "# color_list = ['blue', 'green', 'red', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'pink', 'lime']\n",
    "label = (score_title, assigned_color)\n",
    "for segment in segments:\n",
    "    labeled_segments.append((label, segment))\n",
    "\n",
    "\n",
    "# output to a readable .txt file\n",
    "with open(\"labeled_segments_output.txt\", \"w\") as f:\n",
    "    f.write(f\"Number of segments: {len(labeled_segments)}\\n\\n\")\n",
    "    for idx, tuple in enumerate(labeled_segments):\n",
    "        label, segment = tuple\n",
    "        title, color = label\n",
    "        f.write(f\"{title} Segment {idx+1} ({color}):\\n\")\n",
    "        f.write(f\"{segment}\\n\")\n",
    "        f.write(\"--------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Distance Using TSLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_to_distance_matrix(segments: list[pd.DataFrame], cores=None):\n",
    "    if __name__ == '__main__':\n",
    "        \n",
    "        if cores is not None and cores > cpu_count():\n",
    "            raise ValueError(f\"You don't have enough cores! Please specify a value within your system's number of cores. \\n Core Count: {cpu_count()}\")\n",
    "        \n",
    "        seg_np = [segment.to_numpy() for segment in segments]\n",
    "    \n",
    "        num_segments = len(seg_np)\n",
    "        distance_matrix = np.zeros((num_segments, num_segments))\n",
    "    \n",
    "        # Create argument list for multiprocessing\n",
    "        args_list = []\n",
    "        for i in range(num_segments):\n",
    "            for j in range(i + 1, num_segments):\n",
    "                args_list.append((i, j, segments[i], segments[j]))\n",
    "    \n",
    "        with Manager() as manager:\n",
    "            message_list = manager.list()\n",
    "    \n",
    "            def log_message(message):\n",
    "                message_list.append(message)\n",
    "    \n",
    "            # Use multiprocessing Pool to parallelize the calculations\n",
    "            with Pool() as pool:\n",
    "                results = pool.map(worker.calculate_distance, args_list)\n",
    "    \n",
    "            # Update distance matrix with the results\n",
    "            for i, j, distance, message in results:\n",
    "                distance_matrix[i, j] = distance\n",
    "                distance_matrix[j, i] = distance  # Reflect along the diagonal\n",
    "                log_message(message)\n",
    "    \n",
    "            # Print messages from the shared list\n",
    "            for message in message_list:\n",
    "                print(message)\n",
    "    \n",
    "        return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments to distance matrix\n",
    "dist_mat = segments_to_distance_matrix(segments)\n",
    "print(f\"there are {len(dist_mat)} elements in dist mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the KNN Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building KNN Graph\n",
    "k = 3\n",
    "distance_matrix = dist_mat\n",
    "knn_graph = kneighbors_graph(distance_matrix, n_neighbors=k, mode='connectivity')\n",
    "\n",
    "G = nx.from_scipy_sparse_array(knn_graph)\n",
    "\n",
    "# Detect if the graph is disjoint\n",
    "if not nx.is_connected(G):\n",
    "    print(\"The KNN graph is disjoint. Ensuring connectivity...\")\n",
    "\n",
    "    # Calculate the connected components\n",
    "    components = list(nx.connected_components(G))\n",
    "\n",
    "    # Connect the components\n",
    "    for i in range(len(components) - 1):\n",
    "        min_dist = np.inf\n",
    "        closest_pair = None\n",
    "        for node1 in components[i]:\n",
    "            for node2 in components[i + 1]:\n",
    "                dist = distance_matrix[node1, node2]\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_pair = (node1, node2)\n",
    "\n",
    "        # Add an edge between the closest pair of nodes from different components\n",
    "        G.add_edge(closest_pair[0], closest_pair[1])\n",
    "\n",
    "# Plot the final connected graph\n",
    "pos = nx.spring_layout(G, seed=42, iterations=50)\n",
    "pos_dict = {i: pos[i] for i in range(len(pos))}\n",
    "nx.draw(G, node_size=50, pos=pos_dict)\n",
    "plt.title('Bach Prelude in C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance matrix to knn graph function\n",
    "def distance_matrix_to_knn_graph(k: int, distance_matrix: np.array, graph_title: str,\n",
    "                                 seed: int, iterations: int):\n",
    "  knn_graph = kneighbors_graph(distance_matrix, n_neighbors=k, mode='connectivity')\n",
    "\n",
    "  G = nx.from_scipy_sparse_array(knn_graph)\n",
    "\n",
    "  # Detect if the graph is disjoint\n",
    "  if not nx.is_connected(G):\n",
    "      print(\"The KNN graph is disjoint. Ensuring connectivity...\")\n",
    "\n",
    "      # Calculate the connected components\n",
    "      components = list(nx.connected_components(G))\n",
    "\n",
    "      # Connect the components\n",
    "      for i in range(len(components) - 1):\n",
    "          min_dist = np.inf\n",
    "          closest_pair = None\n",
    "          for node1 in components[i]:\n",
    "              for node2 in components[i + 1]:\n",
    "                  dist = distance_matrix[node1, node2]\n",
    "                  if dist < min_dist:\n",
    "                      min_dist = dist\n",
    "                      closest_pair = (node1, node2)\n",
    "\n",
    "          # Add an edge between the closest pair of nodes from different components\n",
    "          G.add_edge(closest_pair[0], closest_pair[1])\n",
    "\n",
    "  # Plot the final connected graph\n",
    "  pos = nx.spring_layout(G, seed=seed, iterations=iterations)\n",
    "  nx.draw(G, node_size=50, pos=pos)\n",
    "  plt.title(graph_title + f\" (K={k})\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show graph\n",
    "distance_matrix_to_knn_graph(3, dist_mat, \"Bach Prelude in C\", 42, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently Trying to Put The Segment Data Into The Node so we can analyze grouped segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments to graph function\n",
    "def segments_to_graph(k: int, segments: list[pd.DataFrame], labeled_segments, cores=None):\n",
    "  # Convert segments to a distance matrix\n",
    "  distance_matrix = segments_to_distance_matrix(segments, cores=cores)\n",
    "\n",
    "  # Compute the k-NN graph\n",
    "  knn_graph = kneighbors_graph(distance_matrix, n_neighbors=k, mode='connectivity')\n",
    "\n",
    "  # Convert the k-NN graph to a NetworkX graph\n",
    "  G = nx.from_scipy_sparse_array(knn_graph)\n",
    "\n",
    "  # Add segment data as attributes to each node\n",
    "  for i in range(len(segments)):\n",
    "    G.nodes[i]['segment'] = labeled_segments[i] # print shit\n",
    "\n",
    "  # Detect if the graph is disjoint\n",
    "  if not nx.is_connected(G):\n",
    "      print(\"The KNN graph is disjoint. Ensuring connectivity...\")\n",
    "\n",
    "      # Calculate the connected components\n",
    "      components = list(nx.connected_components(G))\n",
    "\n",
    "      # Connect the components\n",
    "      for i in range(len(components) - 1):\n",
    "          min_dist = np.inf\n",
    "          closest_pair = None\n",
    "          for node1 in components[i]:\n",
    "              for node2 in components[i + 1]:\n",
    "                  dist = distance_matrix[node1, node2]\n",
    "                  if dist < min_dist:\n",
    "                      min_dist = dist\n",
    "                      closest_pair = (node1, node2)\n",
    "\n",
    "          # Add an edge between the closest pair of nodes from different components\n",
    "          G.add_edge(closest_pair[0], closest_pair[1])\n",
    "\n",
    "  return G, distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments to graph\n",
    "graph, distance_matrix = segments_to_graph(5, segments, labeled_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to find ways to validate \"Graph Identity\"\n",
    "\n",
    "besides average dtw distance Im trying to see if I can make something of a graph \"silhouette score\".\n",
    "\n",
    "Basically get the communities in the graph then calculate the following:\n",
    "\n",
    "* homogeneity: intra-cluster distance\n",
    "\n",
    "* heterogeneity: inter-cluster distance\n",
    "\n",
    "* \"Graph Silhoette Score:\" $\\frac{Heterogeneity - Homogeneity} {max(Hetero, Homo)}$\n",
    "\n",
    "Also might take a look at clustering coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph metrics function\n",
    "def graph_metrics(graph: nx.classes.graph.Graph, distance_matrix: np.array,\n",
    "                  seed: int):\n",
    "  avg_dtw_distance = distance_matrix.mean()\n",
    "  avg_clustering_coef = nx.average_clustering(graph)\n",
    "\n",
    "  communities = nx.community.louvain_communities(graph, seed)\n",
    "\n",
    "  silhouette_scores = []\n",
    "  for cluster in communities:\n",
    "    for i in cluster:\n",
    "      cluster_distances = distance_matrix[i, list(cluster - {i})]\n",
    "      homogeneity = np.mean(cluster_distances)\n",
    "      other_cluster_distances = [np.mean(distance_matrix[i, list(other_cluster)]) for other_cluster in communities if other_cluster != cluster]\n",
    "      heterogeneity = min(other_cluster_distances) if other_cluster_distances else homogeneity\n",
    "      silhouette_score = (heterogeneity - homogeneity) / max(heterogeneity, homogeneity)\n",
    "      silhouette_scores.append(silhouette_score)\n",
    "\n",
    "  # Average silhouette score for all nodes\n",
    "  average_silhouette_score = np.mean(silhouette_scores)\n",
    "\n",
    "  conductance_scores = []\n",
    "  for cluster in communities:\n",
    "    cluster_conductance = conductance(graph, cluster)\n",
    "    conductance_scores.append(cluster_conductance)\n",
    "\n",
    "  average_conductance = np.mean(conductance_scores)\n",
    "\n",
    "  print(\"Average DTW Distance:\", avg_dtw_distance)\n",
    "  print(\"Average Clustering Coefficient:\", avg_clustering_coef)\n",
    "  print(\"Average Silhouette Score\", average_silhouette_score)\n",
    "  print(\"Average Conductance:\", average_conductance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show graph metrics and segment data\n",
    "graph_metrics(graph, distance_matrix, 42)\n",
    "print(f\"Graph Length: {len(graph)}\")\n",
    "\n",
    "for node in graph.nodes(data=True):\n",
    "  node_id = node[0]\n",
    "  segment_data = node[1]['segment']\n",
    "  print(f\"Node {node_id} segment data:\")\n",
    "  print(segment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph function\n",
    "def plot_graph(graph: nx.classes.graph.Graph,\n",
    "               seed: int,\n",
    "               iterations: int,\n",
    "               title: str,\n",
    "               node_size: int):\n",
    "  pos = nx.spring_layout(graph, seed=seed, iterations=iterations)\n",
    "  for node in graph.nodes(data=True):\n",
    "    segment_data = node[1]['segment']\n",
    "    label, matrix = segment_data\n",
    "    title, color = label\n",
    "    print(color)\n",
    "    # G.nodes[node]['color'] = color\n",
    "  nx.draw(G, node_size=node_size, node_color='red' ,pos=pos)\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show graph\n",
    "plot_graph(graph, 3, 50, \"Bach Prelud in C (K=5)\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graph.nodes())):\n",
    "  graph.nodes[i]['segment'] = graph.nodes[i]['segment'].to_json(default_handler=str)\n",
    "\n",
    "nt = Network('1000px', '1000px', notebook=True, cdn_resources = 'remote')\n",
    "nt.from_nx(graph)\n",
    "nt.show('sample_graph.html')   ### Still need to figure out the labels\n",
    "display(HTML('sample_graph.html'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
