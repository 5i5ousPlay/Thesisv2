\chapter{REVIEW OF RELATED LITERATURE}


\section{Twitter and Other Social Media Sites in Disaster Response}
Social media sites provide a vast amount of easily-accessible data for almost anyone who has internet access and a corresponding device. Even during times of disaster, relevant data still circulate across various social media sites. Previous studies have shown that Twitter has been used as a source of data regarding disaster and emergency related matters \cite{GOOLSBY2010, MCDOUGALL2011, VICTORINOESTUARLAGMAY2016, ROSALES2017, VELASCOBERMEJODOMINGO2018}. One particular occasion for instance, is the series of terrorist attacks in Mumbai, India. The terrorist incidents that took place is 2008 resulted in the portrayal of how social media sites may be seen as a source of real-time crisis related information. Twitter users at the time provided authorities with valuable information by tweeting involving situational reports, requests for assistance, and even documentations of the entire series of attacks \cite{GOOLSBY2010}. This instance showed how impactful Twitter may be in times of crisis. Another occasion where social media sites played a key role in during a time of disaster was when a series of tropical cyclones hit Australia. Queensland, a state of Australia, suffered from floods which dramatically affected the lives of local citizens. Major flooding was experienced in over 30 cities, with the cost of damage amounting to billions of dollars. However, this event saw an unprecedented usage of social media sites by the public sector in assisting the local government to keep the situation under control. Local citizens used Twitter and Facebook to post pictures, videos, and status reports that helped members of both the private and public sectors to minimize the damage caused by the flooding \cite{MCDOUGALL2011}. At the peak of the flooding, it was estimated that there were around fourteen to sixteen thousand tweets per hour that contained the ‘qldfloods hashtag’ which was used to facilitate conversations regarding the disaster. Citizens were even applauded by the national government for their contributions via social media sites.

The role of social media sites in disaster risk management continues to grow throughout the years. Aside from the examples discussed above, social media sites have become a potent source of disaster related information that some disaster management systems have already used Twitter as a primary source of data. One example is a Twitter-mining tool called Tweedr which gathers actionable information for responders during and after a disaster \cite{ASHKTORABBROWNNANDICULOTTA2014}. Another is Senseplace2, a web platform that visualizes tweets to increase situational awareness by providing users with geovisual analytics tools to explore the geospatial characteristics of tweets \cite{HSMM2015}. 

\section{Different Types of Disaster-Related Tweets}
There are several different types of tweets that are tweeted by users at different points in time during a disaster \cite{cat2016,TTC2015}. Tweets vary in content and meaning over time since the state of a particular area changes as a disaster progresses. There are tweets that serve as warnings or notices of preparation (pre-disaster tweets such as tweets regarding the name of an upcoming typhoon and possible areas that might be affected), situational reports and rescue requests (during disaster tweets or tweets that concern cries for help and details on the status of a particular sector), and sentiments regarding memorialization (post-disaster tweets which include relief coordination and well-wishes for affected citizens). 

The identification and categorization of disaster-related tweets were analyzed in 2016 \cite{cat2016}. While situational awareness is important for tweet data analysis, it does not fully capture the entirety of the reactions of those who tweet during times of disaster. This study aimed to address that. The study made use of tweets during Hurricane Sandy in the United States back in October 2012. Keyword collection was performed to collect tweets using keywords from October 23, 2012 to April 5, 2013 such as ‘hurricanesandy’, ‘occupysandy’, and ‘sandycam’ to name a few. 

The study used six categories to classify the collected and filtered tweets \cite{cat2016}. The following categories are: Sentiment, Action, Preparation, Reporting, Information, and Movement. Tweets were to be analyzed and classified using annotators and classification models. Two annotators were trained using a segment of tweets in order to design a multi-label schema which annotates tweets that reflect attitudes, information sources, and protective decision-making behavior of those who tweeted. The annotation process involved labeling tweets for relevance, and labeling relevant tweets with their respective categories.

The results of the fine-grained annotations in the study showed that the hardest categories relative to percentage of tweets and k score agreement are Preparation and Movement, while the ones with the most confusions are Preparation, Reporting, and Sentiment. 

\subsection{Methods in Classification}
Support vector machines (SVMs) were the chosen type of classification model for the study as it yielded the best performance measures using feature selection. The baseline features of the study were the counts of unigrams in preprocessed tweets (removal of capitalization, punctuation, and stopwords). Other features such as bigrams, the time of the tweet, whether or not a tweet is a retweet, a tweet’s URL, and word embeddings were also used in the study. 

Classification performance results were computed using the baseline feature (unigrams) only, all the features mentioned, and the best features for each category. It was found that the time, context, and word embeddings features generally help in relevance classification. The most confused categories in terms of classification were Information and Reporting, while the worst performing ones were Movement, Action, and Preparation. The study does discuss that the scores of certain categories were influenced by the sparse dataset they used (e.g. Movement category lacks data). 

Overall, tweets that fall under the categories of Reporting, Information, and Sentiment were the highest in terms of number, annotation score, and classification score despite confusion metrics. In other words, most of the tweets that were collected and analyzed were tweeted during the time of the actual disaster \cite{cat2016}. These were tweets concerned with disseminating first-hand information, spreading news, and expressing emotions, which was also highlighted by the study. Further recommendations of the study dealt with real-time implementation of the methods described onto a real-time, existing platform.

\section{Analysis of Different Types of Tweets During Typhoon Yolanda}
It was mentioned in section 1.5 that this study will be using tweets during Typhoon Yolanda/Haiyan for its purposes. It has been established that there are different types of tweets tweeted at different points in time during a disaster. The case of Typhoon Yolanda is no exception. Citizens in the Philippines and even in other countries used Twitter as a platform to communicate their thoughts and messages when Typhoon Yolanda hit the archipelago \cite{TTC2015}. 

Communication patterns from tweets during Typhoon Yolanda were analyzed in 2015 \cite{TTC2015}. One of the main objectives of the study was to identify the different purposes of the tweets that users from the Philippines tweeted at the time of the disaster. Tweets between November 8, 2013 to November 13, 2013 were collected, a five day span of when the typhoon made landfall in the Philippines. The qualitative software using NVivo was used for data collection. Tweets were collected at three separate time points on each of the five days based on hashtags such as ‘#PrayforthePhilippines’, and ‘#Haiyan’. A random sample of 1000 tweets was then selected for analysis. The majority of the selected tweets were in English, with only a fraction being in the local language Filipino. Only English tweets were analyzed as a result. Over half of the selected tweets were from ordinary citizens, a fifth were from news organizations, and a tenth were from journalists \cite{TTC2015}. 

Analysis was done by first downloading tweets along with metadata such as username, geographic location, and hashtags. Metadata on user geographic location was recoded in order to identify if a tweet was tweeted in the Philippines, outside the Philippines, or unidentified. The selected tweets were then coded, first based on what type of user tweeted a particular tweet (e.g. ordinary citizen, NGO, journalist), and second, based on derived categories of social media use during a disaster. These derived categories are: reporting on the situation from a personal perspective, secondhand reporting, requesting help, coordinating relief efforts, providing mental counseling, criticizing the government, memorializing, discussing causes, and connecting community members.  

Results show that the most common purpose of tweets during Typhoon Yolanda was to report secondhand information. This concerns tweeting about information sourced from other entities such as news reporters, government sites, or testimonies from affected residents. The second most common purpose was memorializing, which concerns expressing sentiments and well-wishes for those affected by the typhoon. The third most common purpose was coordinating relief efforts, tweets that were aimed at organizing relief and rescue operations and calls for donations. This shows that most of the analyzed tweets were tweeted during the time of the actual disaster.

The study also touched on how different types of users used Twitter during the disaster \cite{TTC2015}. It was observed that news organizations, journalists, and government bodies used Twitter mainly for secondhand reporting, while ordinary citizens and celebrities used Twitter for memorializing, and NGOs used Twitter for relief coordination. The relationship between time and Twitter usage was considered as well. Volumes of certain types of tweets changed as Typhoon Yolanda progressed. Number of tweets concerned with secondhand reporting and memorializing were high in number during the first few days of the disaster, but gradually decreased as time passed. On the other hand, the number of tweets concerned with relief coordination was low in volume at first but increased after the storm hit, which indicates an increase in post-disaster response by members of the community.

Another key observation made in the study is the absence of further potential uses of Twitter \cite{TTC2015}. It appeared that the usage of Twitter during Typhoon Yolanda could still be further organized despite apparent communicational patterns. It was seen that particular entities would only be active in tweeting for a given time period during the typhoon. Users used Twitter for traditional purposes instead of maximizing its non-traditional affordances as a non-traditional media platform. A good example is the case of government bodies; government bodies used Twitter for secondhand reporting, but not sufficiently for relief coordination. In this case Twitter could have been used as a platform for better disaster preparedness given its accessibility as a social media site. Journalists did report secondhand information, but the needs of the public go beyond access to secondhand information in the case of a disaster such as Typhoon Yolanda. Affected citizens also did not use Twitter as much to request for assistance during certain points of the Typhoon. Usage of Twitter during times of disasters may still be further explored as the study alludes to.

\section{Previously Explored Approaches to General Location Approximation }
Location is an important aspect of tweets in the context of disaster risk reduction and response. There are several ways of approximating the location of non-geotagged tweets. The location of geotagged tweets are generally recorded and read in the form of latitude-longitude coordinates. Previous methods on approximating the location of tweets without proper latitude-longitude data have been explored \cite{carmen, GFC2012, OBCS2013,ROSALES2017,VELASCOBERMEJODOMINGO2018}. The following section will briefly discuss some of the more common features and approaches used in the location approximation of tweets. 

\subsection{Using ``Place'' JSON Objects}
There are APIs and programs, such as the Twitter Streaming API, that are used to collect tweets from Twitter. Some tweets return a JSON “Place” object which contains coded information regarding that particular tweet \cite{OBCS2013, GFC2012, carmen}. Information such as the country and city of where the tweet was sent from can be found, as well as geographic coordinates. Some Place types include even finer-grained information like street addresses. Twitter itself already performs geolocation for tweets with Place objects. Place objects may be extracted and filtered using various libraries available online \cite{tweepy}.

\subsection{Latitude/Longitude Coordinates of Tweets}
Some tweets contain geographical information in the form of latitude/longitude coordinates. Twitter users may tag their tweets with latitude/longitude coordinates by enabling the location feature of their devices as they tweet. Tweets with latitude/longitude coordinates available indicate the exact location of where a tweet was tweeted from, but they do not necessarily contain fine-grained information unlike tweets with Place objects \cite{OBCS2013, GFC2012, carmen}. Tweets with geographical coordinates are usually used as references in the location approximation of tweets without latitude/longitude data \cite{ROSALES2017, VELASCOBERMEJODOMINGO2018}. Approaches that involve latitude/longitude data include reverse geocoding (translating coordinates to actual locations like cities or provinces) \cite{carmen}, and convex hull geometrics \cite{ROSALES2017, VELASCOBERMEJODOMINGO2018}.

\subsection{User Profile Information}
Twitter allows users to specify a location in the location text field of their profiles. This location is understood to be where a particular user hails from. Tweets from Twitter users who do not turn on their location services when they tweet but have specified locations in their profiles may still be counted as geolocated tweets. The string value that users provide in their profiles may be geocoded and translated \cite{OBCS2013, GFC2012, carmen}. Existing map APIs can resolve profile location strings to structured locations, possibly in the form of latitude/longitude coordinates. It is important to note that geocoded and translated locations are mostly static, which may be problematic since Twitter users may tweet at different locations from their specified ones. Another potential problem is that users may lie or provide nonsensical text in their profiles, which affects approximation accuracy \cite{L12011, L22014}.

\subsection{Content-Based Geolocation}
Tweet content may be analyzed in order to tag a particular tweet with a given location. Factors such as a user’s dialect, mentions, and references may be used to infer where a particular user is located. This particular approach to location approximation is mainly for tweets from users who do not provide explicit location information. There are various possible implementations regarding this approach. One involves analyzing a tweet for mentions of Places of Interest (POI), or terms that pertain to landmarks that may be traced to certain locations in order to approximate the location of a given non-geotagged tweet \cite{L22014, CHENGCAVARLEELEE2010}.  Another involves the application of the Latent Semantic Analysis algorithm, a method of implementation that builds on the assumption that every defined geographic region contains a unique set of word distributions that may be used to geolocate a tweet based on text tweet content \cite{ROSALES2017, VELASCOBERMEJODOMINGO2018}.

\section {Previous Works on Location Approximation in The Context of Typhoon Yolanda }
This study will be based on previous studies regarding the location approximation of non-geotagged tweets during Typhoon Yolanda. Past works have proposed various solutions on how to locate a non-geotagged tweet by using already geotagged tweets as reference. The following section will discuss two previously conducted and related studies that implemented and tested possible location approximation solutions to geolocating tweets in the context of Typhoon Yolanda.

\subsection{Geolocation Approximations to Disaster Related Tweets}
Numerous methods of location approximation involving tweets during Typhoon Yolanda were proposed and explored in 2017 \cite{ROSALES2017}. The particular study made use of local and international tweets tweeted during typhoon Yolanda (internationally known as Haiyan) that contain certain keywords like ‘ulan’, ‘bagyo’, ‘typhoon’, and ‘#Yolanda’. The coordinates of the path of Typhoon Yolanda were also referenced by the study in its work. This study used the latitude/longitude coordinates of tweets as the main feature for location approximation. The study began with an analysis on the spatio-temporal characteristics of disaster related tweets. This was done by looking at the location of the geotagged tweets, the trajectory of different sets of located tweets, and the location of disaster affected areas at different time segments. Sets of computations regarding the correlation among typhoon trajectory, tweet trajectory, and location of disaster affected areas, the relationship between a given number of tweets and the area covered by these tweets, and others were also included in the study \cite{ROSALES2017}.

Tweet texts were converted to document term matrices and fed to an LDA model to perform topic analysis. This was done in order to determine certain themes within a given collection of words that will help determine the location of a certain group of tweets \cite{ROSALES2017}.

Models for disaster location relative location prediction were created to test the theory that distinct regions regarding disaster related information are not geopolitically defined but are determined based on an area’s relative distance to the typhoon or to the disaster affected area. The developed models were used to predict a tweet’s relative distance to the typhoon or the disaster affected area. Tweet texts within defined distances were mined and tokenized before being transformed into a tf-idf matrix. Groups of tweets were compared in order to determine if a particular group belongs to a certain region by predicting the approximated distance from that of the affected area and the eye of the typhoon \cite{ROSALES2017}.

The study also touched on semantic similarity based location approximation models. The study proposed the theory that semantically similar tweets most likely hail from geographically close locations. This particular model made use of three semantic modeling methods: LSA, doc2vec, and tf-idf. The LSA (Latent Semantic Analysis) algorithm was used to measure the semantic similarity of text corpora. Doc2vec was used to generate vector representations of text documents. TF-IDF matrixes were used to determine the importance of a particular word within a corpus. These three tools were used to determine the most semantically similar tweets to a given untagged tweet. In this portion, the location of a non-geotagged tweet was approximated using the coordinates of the most semantically similar tweets to it. Another model was discussed which used three semantic modeling methods \cite{ROSALES2017}.

The created models in the study yielded a variety of results. For the models regarding disaster location relative location prediction, it was found that models for smaller time segments produce better results. Regarding the measurements involving predicting which region a particular group of tweets approximately belong to, it was found that the result is related to the number of tweets in that distance segment. As for location prediction based on the distance of a non-geotagged tweet from the affected area and the typhoon, it was shown that looking at the distance of the query from the affected area produced significantly higher rates of correct predictions \cite{ROSALES2017}. 

For the first model concerning semantic similarity based location approximation, results indicated that the less tweets used for weighted center computation, the better the results. As for the second semantic similarity based model, results showed that there were no significant differences in measurements among the three semantic models \cite{ROSALES2017}.

The recommendations of this study emphasized how semantic based modeling was still in its initial stages. Rigorous testing and more data analysis were suggested in order to determine if the proposed methods of latitude and longitude approximation are appropriate. The study mentioned how the application of the methods tested onto an actual program/site may be helpful in measuring for the accuracies of each \cite{ROSALES2017}.

\subsection{Implementation of Geolocation Approximation Feature for Disaster Systems}
This section will detail a study that continues the work of the study discussed in section 2.2.1. A full pipeline application consisting of four major components was developed and deployed as a service for public use. The four major components are the Tweet Collection Module, the Approximation API, the Geolocation Module, and the Visualization Module. Tweets collected via Twitter’s Streaming API in the Tweet Collector Module are passed to the Approximation API, which connects the Tweet Collector to the Geolocation Module. The Geolocation Module uses Gensim’s (an extended Python library) LSI implementation as a semantic similarity based approach to location approximation. Latent Semantic Indexing (LSI) is similar to LSA, one of the semantic similarity based algorithms discussed in the section 2.2.1. Finally, results produced by the Geolocation Module are displayed using the Visualization Module \cite{VELASCOBERMEJODOMINGO2018}.

The geolocation features of the application are linked with eBayanihan, an existing web and mobile disaster risk management platform in the Philippines that mainly relies on crowdsourced data. The process of the LSI implementation in this study is similar to that the LSA algorithm implementation in the study in section 2.2.1. This study looked at the top ten semantically similar tweets to the said query will be used to form a convex hull with the weight of a given edge equivalent to the query’s percentage of semantic similarity with that particular tweet. Afterwards, the geometric and weighted centers of the convex hull will be calculated to approximate the location of the non-geotagged tweet \cite{VELASCOBERMEJODOMINGO2018}.

Findings show that for one, the geometric center of the convex hull may be used as a substitute for the weighted center regarding the approximation of the latitude and longitude coordinates of a non-geotagged tweet. However, in terms of overall results, most had high standard deviation values, both using lemmatized and non-lemmatized datasets. Another key observation in the study is that narrowing the location range of tweets helped produce more accurate results (lower standard deviation). Meaning, when the possible range approximated values is segmented for further to for example, per region, then more accurate results would be produced. The developed pipeline became available for use online \cite{VELASCOBERMEJODOMINGO2018}. 

Recommendations of the study emphasized that a possible way to implement the method used to produce more accurate results is to segment the geographical territory of the Philippines according to regions. This follows the study’s findings about how the smaller the location range of the tweets, the more accurate the results become. By segmenting the area into regions, perhaps a more accurate set of results will be produced \cite{VELASCOBERMEJODOMINGO2018}. 

